# 内存原理( 姑且浅浅的记一下笔记 )

***

通过C语言取地址得到的是虚拟地址, 虚拟地址经过CPU运算得到实际地址, 有意思的是每个变量在内存中的地址不是一成不变的, 内存如果发生变化的话则需要重新通过CPU计算变量在内存中的地址( 即使是汇编语言也会有内存地址的变化 ), 每次运行程序变量的地址都会变化, 且虚拟地址也为程序提供了内存中的间隔, 较为有效的避免了内存被其他进程使用. 使用了虚拟地址后, 程序A和程序B虽然都可以访问同一个地址, 但它们对应的物理地址是不同的, 无论如何操作, 都不会修改对方的内存

确定操作系统最大的虚拟内存方法: cpu为多少位一般指针也是多少位, 指针最大可以指向的地址就是虚拟内存的最大范围例如: 32位CPU指针大小为32位2^32 = 4G 内存可以使用的最大值为4G, 更大的内存也无法使用了. 值得注意的是64位CPU只用低位的48位用来定位虚拟地址, 因为2^64是一个很大的值( 约为17179PB ), 48位可以定位的虚拟内存为256TB. 

#### 内存步长 ( CPU一次寻址内存大小就是内存步长, 32位步长为4字节, 64为步长为8字节 )

***

一次读取数据大于步长则有不足, 少了浪费, 因此32位CPU总是一次读取4字节的数据, 在内存中表现为从 0,4,8,12开始读取. 一个变量如果在步长内可以读取则一次即可将数据读入, 但是如果一次不能读取进入则需要将多次读取的数据进行拼接. 在编程过程中会存在内存对齐的情况, 即尽可能使内存大小为n步长可以读取到( 中间可能会有内存填充情况 ); 

#### 内存的非法访问底层原理

***

程序A和程序B在内存中因为有虚拟内存将两个程序的内存分割开来, 并没有重叠的可能, 如果A程序访问内存超过了分配给A程序的内存地址就意味着内存非法访问, 拒绝了访问内存的请求, 大概率会将程序强制关闭.

#### 内存分页机制

***

一个程序在运行的过程中一段时间内只会频繁的使用一部分数据, 如果一次将程序全部加载进入内存则会造成大量的内存的读写, 严重影响内存使用效率, 因此采取了分页机制, 将所需要的数据分块(分页)写入内存或写入硬盘当中, 这样有利于内存的效率提升. 且页的大小是由硬件决定的, 有可能是4kib或其余的大小, 且同一时间只能选择一种页的大小. 
如果程序A将一部分数据映射到实际内存的p0, B程序将一部分数据也映射到实际内存的p0则这样就会实现内存共享. 如果程序A要使用数据不在内存当中则需要将程序从硬盘读取到内存当中( 页错误 )

#### 内存分页机制的实现

***

内存地址的转换是通过页表实现的. 如果知道一个页的大小( 一般是4K大小 ) 知道数据在在多少页, 页内的偏移就可以找到实际内存地址, 例如第十二页, 页内偏移量为 240 则内存地址是 2^12 * 12 + 240 = 4096\*12+240 = 49392 
假设为32位系统, 则最大内存为 2^32, 页的大小为4k (2^12) 因此页的数量为2^32/2^12 = 2^20, 只要定义一个数组, 数组大小为2^20 = 1M 即可存储全部的页, 因此这个数组叫做页表( 页表的实际大小为4M ). 一个int类型的大小为4字节 32 位, 需要20位用于存储页表在多少页, 剩下有12位被用于表示页内偏移量及部分文件信息( 文件属性 ), 具体实现则是 页表数组中每一个 int 类型变量的内存高20位用于记录了页表, 低位12位用于记录了业内偏移量. 

##### 二级页表

***

二级页表可以表示为2^10 \* 2^10 ,也就是说将一级页表拆分成 1024 个页表
二级页表的优点是: 比起一级页表, 二级页表每个页表分配的内存更小, 相对来说更加灵活的操作内存, 一级页表无论程序多大都必须分配一级页表的最大内存表达, 造成内存的占用和浪费, 相比起一级页表, 二级页表更能够适应多线程. 两级页表的一个明显优点是, 如果程序占用的内存较少, 分散的小页表的个数就会远远少于1024个, 只会占用很少的一部分存储空间 ( 远远小于4M ) 
二级页表存储在内存中并不是连续的而是离散的, 因此不能使用指针指向每一个页表, 此时使用一个数组( 大小为1024 ) 来记录每个页表的位置, 也就是通过页目录来记录每个页表的位置, 因此使用一个指针指向页目录, 利用页目录找到页表, 再使用页表找到实际内存地址( 将页目录的32位分为三部分, 高10位用于存储页目录中元素的下标, 中间10位用于存储页表的下标, 最后12位用于存储页内偏移量 )

### CPU中的MMU( 内存管理单元 )

***

由于页映射下得到的是虚拟地址, 虚拟地址到实际物理地址需要通过MMU计算( 页表/页目录一般存储到MMU的缓存中, 如果页表较大无法在缓存中存下则将剩余的页表存储到内存当中, 但是缓存的命中率高达90, 很少使用内存当中的页表 ), 并且MMU可以进行内存管理( 通过页表的低位12位来查看页表的页内偏移量, 是否有权限进行内存的使用 ), 需要内存进行映射的时候有限检查低位12位, 检查是否有权限写入, 有权限的话执行, 沒有权限则报为异常, 终止程序运行. 

### 内核空间与用户空间 ( linux与windows )

***

对于32位的操作系统来说只能使用4GiB的内存, 操作系统要将内存的高位空间占用, 将操作系统内核加载进入这部分空间. 对于32位的linux来说一般占用1或2GiB空间作为内核空间, 剩余内存作为用户空间( 栈用于加载运行时的函数( 包括临时变量, 函数地址及调用信息以及, 临时对象 函数结束之后即可释放栈中内存, 堆区为malloc或new的内存 ). 以下为示例图<img src="https://www.54benniao.com/uploads/allimg/230330/14140214C-0.jpg" alt="linux32位内存示例" />


对于64位操作系统来说与32位操作系统类似, 不过有一点需要注意64位操作系统一般可以使用的位是48位( 一方面是不需要64位作为内存, 48位足够, 另一方面48位是受限于各项硬件 ), 由于只使用了48位作为运算因此任何虚拟地址的48位至63位必须与47位一致. 
![64位linux内核](https://www.54benniao.com/uploads/allimg/230330/1414021547-1.jpg)

由于windows是闭源因此只能从官方文档查看, 32位图示, 64位不再深入研究![32位windows内存](https://www.54benniao.com/uploads/allimg/230330/14145I200-0.jpg)

### 内核态与用户态

***

操作系统内核当中存储操作系统的内核, 其中拥有很多用于向上提供的接口, 想要调用这些接口就需要从用户态切换为内核态, 修改内核当中的数据十分危险, 很有可能导致系统崩溃, 所以操作系统禁止用户程序直接访问内核空间. 想要访问操作系统内核必须使用API接口, 当需要使用比较底层的操作时会进入内核态, 执行完成底层操作之后就会切回用户态. 内核的主要作用是管理底层的硬件, 包括( 鼠标, 键盘, 显示器, 打印机等 ). 内核对用户程序是充分不信任的, 

### 内存当中的栈

***

栈（Stack）可以存放函数参数, 局部变量, 局部数组等作用范围在函数内部的数据, 栈的用途就是完成函数的调用. 栈就是数据结构当中的栈, 其特点是先进后出, 出栈入栈都经过栈顶. 对每个程序来说可用的栈已经在编译时期确定( 一个程序可以包含多个线程, 每个线程都有自己的栈, 严格来说, 栈的最大值是针对线程来说的, 而不是针对程序 ), 且不同编译器对栈的大小定义不同, GCC默认为8MiB. 如果一个程序使用栈的内存大于栈定义的内存则说明会发生栈溢出, 一个函数在栈中所记录的信息有 ( 函数调用之前的的数据需要记录, 用于知道应该怎样才能找到之前程序运行的实际地址, 这些数据位于最底层( edi, esi, ebx等寄存器位于最底层, 但是ebp位于内存上层用于定位参数).  之后会有一块内存用于存储局部变量返回值等. ) 
![栈模型](https://www.54benniao.com/uploads/allimg/230330/141AIY6-1.jpg)

函数调用之后会将所需要的数据进行传入, 其过程应该为如下图所示( 值得注意的是很有意思地方是函数数据并未消除, 也就是说如果及时调用地址的话可以找到, 只有程序数据继续加大的时候才有可能数据被覆盖 )

![函数的调用, 栈的使用](https://www.54benniao.com/uploads/allimg/230330/141Q364S-0.jpg)

### 内存当中的堆

***

堆区内存唯一是可以由程序员自行选择分配的内存, 使用malloc( 分配size的内存 ), calloc( 分配n*size的内存 ), relloc( 对指向ptr的内存重新分配size的内存 ), free函数进行内存的分配, 值得注意的是free() 只会释放内存但不会将指针指向NULL, free指针之后会形成野指针, 很危险, 需要将指针指向NULL.  为了提升程序的性能, 一般会申请一块比较大的内存, 其余操作在该内存内再利用( 优先从内存的地地址分配 ), 过程类似链表( 本质上就是利用链表来查找分配内存 ), 很容易造成内存碎片.  

题外话: 数据总线和地址总线不是一回事, 数据总线是在内存和CPU之间传递数据, 而地址总线用于在内存上定位地址. 所谓的内存池, 线程池等等一系列的池类技术都是先申请很多的资源, 在需要时候进行人为管理, 不需要时进行人为释放或睡眠.